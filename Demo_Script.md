# 15-Minute Demo — Voiceover Script

## Intro and problem

This demo shows a production-style multi-agent e-commerce support system. The problem we’re solving is scale, consistency, and escalation. When support volume grows, it’s hard to keep answers consistent, to reuse past resolutions, and to know when to hand off to a human. Our solution is eight specialized agents that work together over the A2A protocol: Ingestion, Planner, Intent, RAG, Memory, Reasoning, Response, and Guardrails. We combine a knowledge base with RAG, episodic memory for past incidents, and guardrails so that when the system can’t answer confidently, it creates a ticket and escalates. The result is a single pipeline that can answer from policy, from FAQ, from similar past cases, or escalate to a human when needed.

## Architecture at a glance

The system has eight agents in sequence. The Ingestion Agent normalizes incoming tickets and queries. The Planner Agent decides the execution strategy: it plans the flow, including when to call Intent, when to run RAG and Memory in parallel, and when to hand off to Reasoning and Response. The Intent Agent classifies the request: what’s the topic, what’s the urgency, and what kind of answer we need. The RAG Agent searches our vector store—ChromaDB—over policy documents and FAQs. The Memory Agent uses mem0 and SQLite to recall past resolved incidents so we can reuse similar resolutions. The Reasoning Agent correlates what we found from RAG and Memory with the user’s intent and decides what to use. The Response Agent synthesizes a clear, human-readable answer. The Guardrails Agent runs safety and confidence checks and, when the answer isn’t good enough or the request is out of scope, triggers escalation and ticket creation. All of this is orchestrated by a Host Agent that speaks A2A and calls each agent in turn. The React UI talks to the Host over HTTP and Server-Sent Events so the user sees real-time status as each agent runs. We use three data stores: PostgreSQL for tickets, sessions, and task state; ChromaDB for RAG embeddings; and SQLite plus mem0 for the Memory Agent’s episodic and semantic memory.

## Setup in one command

To run the whole stack we use Docker Compose. You clone the repo, create a dot env file with your API keys—for example Google API key and OpenAI API key for the models—and then run docker-compose up build. That brings up PostgreSQL, ChromaDB if you use it in the stack, and all the agent containers. You may need to run RAG ingest once to load policies and FAQs into the vector store, and optionally seed mem0 with past incidents for the Memory Agent. When everything is up, the React UI is at localhost twelve thousand and the Host Agent is at localhost eight thousand eighty-three. The README has the exact steps and environment variables.

## Live demo: Chat and four scenarios

We’ll use the React UI chat and run four queries that match our test cases. You’ll see the status line update in real time over Server-Sent Events as each agent runs: first Ingestion, then Planner, Intent, RAG, Memory, Reasoning, Response, and Guardrails.

First scenario: a policy question. The user asks: “What is your return window? How many days do I have to return an item?” The Ingestion Agent normalizes the query. The Planner plans the flow. Intent classifies it as returns and policy. RAG queries the vector store and retrieves chunks from the returns-and-refund policy—for example “within thirty days of delivery.” Memory may not find a closer match. Reasoning prefers the RAG policy content. Response synthesizes an answer that cites the policy: items may be returned within thirty days of delivery for a full refund, with the usual conditions. Guardrails passes because the response references the policy. The user gets a clear answer and no ticket is created.

Second scenario: the policy doesn’t have the answer but the FAQ does. The user asks: “Why is my coupon code not working at checkout? I have a screenshot and my cart meets the minimum.” Intent classifies it as promotions and checkout. RAG may get weak hits from policy but stronger hits from the FAQ—for example the exact question “Why is my coupon code not working at checkout?” Reasoning uses that FAQ content: common reasons like expired code, minimum not met, case-sensitive, or combination rules, and the next step—contact support with the code and screenshot for manual verification. Response turns that into a clear answer. Guardrails passes. The user is satisfied and no ticket is created.

Third scenario: RAG can’t fully answer but Memory can. The user says: “I was charged twice for the same order when I clicked Place Order twice because the page was slow. Can you refund one of the charges?” RAG might find generic refund or payment policy but not this specific duplicate-charge scenario. The Memory Agent searches episodic memory and finds a past incident—for example INC-2025-001—where we resolved the same situation: customer charged twice, we verified the duplicate and refunded the duplicate order, and advised waiting for confirmation before refreshing. Reasoning uses that resolution. Response synthesizes an answer: we can help, in similar cases we verify the duplicate and refund it, please send your order number, and we recommend waiting for the order confirmation before refreshing. Guardrails passes. The user gets a resolution path without escalation.

Fourth scenario: escalation. The user asks: “I need a bulk quote for fifty thousand units with custom branding and net-sixty payment terms. Who can I talk to?” Intent classifies it as sales and B2B. RAG and Memory don’t have a good answer for bulk quotes, custom branding, or net-sixty terms. Reasoning concludes we can’t answer confidently. Response can still say something polite: this type of request is handled by our sales team, we’re creating a ticket and a specialist will contact you. Guardrails detects that escalation criteria are met—query outside knowledge, complex B2B—and triggers ticket creation. A ticket is written to PostgreSQL with title, description, status, and priority. The user is told that a ticket has been created and that sales will follow up.

## Flow under the hood

When a message hits the Host, it creates a task and sends the message to the Ingestion Agent. Ingestion normalizes the text, extracts priority and customer context, and may create or update a ticket in PostgreSQL. The Host then calls the Planner Agent. The Planner returns a plan: run Intent, then RAG and Memory in parallel, then Reasoning, then Response, then Guardrails. The Host executes that plan. It calls the Intent Agent to get classification and urgency. It calls the RAG Agent and the Memory Agent in parallel; RAG returns relevant chunks from policies and FAQs, Memory returns similar past incidents if any. The Reasoning Agent receives those results and the intent and decides what to use and how to combine them. The Response Agent turns that into a single, readable answer. The Guardrails Agent checks the response for safety and confidence; if the query is out of scope or the answer isn’t good enough, Guardrails can trigger escalation and the Host or a downstream step creates a ticket in the database. The final response and any ticket ID are sent back to the UI. The React app shows the answer and, if you have observability enabled, you can see the full trace in Langfuse.

## Observability

If you configure Langfuse with public and secret keys in the environment, the Host Agent can send traces for each request. You’ll see the full chain: Ingestion, Planner, Intent, RAG, Memory, Reasoning, Response, Guardrails—with timing and inputs and outputs. The React UI can send a user identifier—for example via the X-User-Phone header—so you can trace requests by user. If Langfuse isn’t set up, the system still runs; we just mention in the demo that traces can be sent to Langfuse for debugging and monitoring.

## Data and training

Knowledge comes from three places. Policies live under training-docs policies: returns and refunds, payment, shipping, account security, order cancellation. FAQs live under training-docs FAQs—for example the e-commerce FAQ with “Why is my coupon code not working at checkout?” We run a RAG ingest script that chunks these documents, embeds them, and loads them into ChromaDB so the RAG Agent can retrieve by semantic similarity. Past incidents are stored for the Memory Agent: we have a seed script that loads past-resolved incidents—like the duplicate-charge case INC-2025-001—into mem0. So when a user asks something that matches a past incident, Memory can return that resolution and the Response Agent can adapt it for the current query. The duplicate-charge scenario in the live demo depends on having run that memory seed script so mem0 has the incident.

## Codebase and extensibility

The repo is organized by component. Under agents there’s one folder per agent: host agent, ingestion, planner, intent, rag agent, memory agent, reasoning, response, guardrails. Each agent has an A2A server entry point—for example __main__ dot py—and an executor that talks to the Host. The React UI lives under react-ui and calls the Host’s HTTP API and SSE endpoint. The database module has models, connection, services, and Alembic migrations for PostgreSQL. Docker Compose wires up Postgres, ChromaDB if needed, and all the agent containers. To add or change an agent you implement the A2A protocol—expose an agent card and handle send message—and register the agent’s URL with the Host. The Host discovers agents by URL and calls them in the order dictated by the Planner. So the pipeline is extensible without changing the Host’s core logic.

## Wrap-up

We showed a multi-agent e-commerce support system: eight agents over A2A, with RAG for policies and FAQs, Memory for past incidents, and Guardrails for safety and escalation. We ran four scenarios—policy answer, FAQ answer, memory-based resolution, and escalation with ticket creation—and walked through the flow and the data stores. Setup is one command with Docker Compose, and observability is optional via Langfuse. The repo and README have the rest. Happy to take questions.
