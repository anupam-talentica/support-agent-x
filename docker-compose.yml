version: "3.8"

services:
  postgres:
    image: postgres:16-alpine
    container_name: support_agents_postgres
    environment:
      POSTGRES_USER: support_user
      POSTGRES_PASSWORD: support_pass
      POSTGRES_DB: support_agents_db
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U support_user -d support_agents_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - support_agents_network

  # Ingestion Agent - Port 10001
  ingestion_agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_ingestion
    env_file: .env
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      LITELLM_MODEL: ${LITELLM_MODEL:-openai/gpt-4.1-mini}
      APP_URL: http://ingestion_agent:10001
    ports:
      - "10001:10001"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - support_agents_network
    command: python -m agents.ingestion_agent.__main__ --host 0.0.0.0 --port 10001
    restart: unless-stopped

  # Intent Classification Agent - Port 10003
  intent_agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_intent
    env_file: .env
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      LITELLM_MODEL: ${LITELLM_MODEL:-openai/gpt-4.1-mini}
      APP_URL: http://intent_agent:10003
    ports:
      - "10003:10003"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - support_agents_network
    command: python -m agents.intent_agent.__main__ --host 0.0.0.0 --port 10003
    restart: unless-stopped

  # Reasoning Agent - Port 10014
  reasoning_agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_reasoning
    env_file: .env
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      LITELLM_MODEL: ${LITELLM_MODEL:-openai/gpt-4.1-mini}
      APP_URL: http://reasoning_agent:10014
    ports:
      - "10014:10014"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - support_agents_network
    command: python -m agents.reasoning_agent.__main__ --host 0.0.0.0 --port 10014
    restart: unless-stopped

  # RAG Agent - Port 10012
  rag_agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_rag
    env_file: .env
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      CHROMA_HOST: ${CHROMA_HOST:-host.docker.internal}
      CHROMA_PORT: ${CHROMA_PORT:-8000}
      CHROMA_COLLECTION: ${CHROMA_COLLECTION:-support-agent-x-openai}
      APP_URL: http://rag_agent:10012
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "10012:10012"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - support_agents_network
    command: python -m agents.rag_agent.__main__ --host 0.0.0.0 --port 10012
    restart: unless-stopped

  # Response Agent - Port 10007
  response_agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_response
    env_file: .env
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      LITELLM_MODEL: ${LITELLM_MODEL:-openai/gpt-4.1-mini}
      APP_URL: http://response_agent:10007
    ports:
      - "10007:10007"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - support_agents_network
    command: python -m agents.response_agent.__main__ --host 0.0.0.0 --port 10007
    restart: unless-stopped

  # Planner Agent - Port 10002
  # Depends on Intent, Reasoning, RAG, and Response agents being ready
  planner_agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_planner
    env_file: .env
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      LITELLM_MODEL: ${LITELLM_MODEL:-openai/gpt-4.1-mini}
      INTENT_AGENT_URL: http://intent_agent:10003
      REASONING_AGENT_URL: http://reasoning_agent:10014
      RAG_AGENT_URL: http://rag_agent:10012
      RESPONSE_AGENT_URL: http://response_agent:10007
      MEMORY_AGENT_URL: http://memory_agent:10005
      APP_URL: http://planner_agent:10002
    ports:
      - "10002:10002"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      intent_agent:
        condition: service_started
      reasoning_agent:
        condition: service_started
      rag_agent:
        condition: service_started
      response_agent:
        condition: service_started
      memory_agent:
        condition: service_started
    networks:
      - support_agents_network
    command: >
      sh -c "
        echo 'Waiting for Intent, Reasoning, RAG, and Response agents to be ready...' &&
        sleep 5 &&
        python -m agents.planner_agent.__main__ --host 0.0.0.0 --port 10002
      "
    restart: unless-stopped

  # Host Agent - Port 8083
  # Depends on Ingestion and Planner agents being ready
  host_agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_host
    env_file: .env
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      LITELLM_MODEL: ${LITELLM_MODEL:-openai/gpt-4.1-mini}
      INGESTION_AGENT_URL: http://ingestion_agent:10001
      PLANNER_AGENT_URL: http://planner_agent:10002
      MEMORY_AGENT_URL: http://memory_agent:10005
      APP_URL: http://host_agent:8083
      # Langfuse observability (optional; leave unset to disable)
      LANGFUSE_PUBLIC_KEY: ${LANGFUSE_PUBLIC_KEY:-}
      LANGFUSE_SECRET_KEY: ${LANGFUSE_SECRET_KEY:-}
      LANGFUSE_BASE_URL: ${LANGFUSE_BASE_URL:-https://cloud.langfuse.com}
    ports:
      - "8083:8083"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      ingestion_agent:
        condition: service_started
      planner_agent:
        condition: service_started
    networks:
      - support_agents_network
    command: >
      sh -c "
        echo 'Waiting for Ingestion and Planner agents to be ready...' &&
        sleep 5 &&
        python -m agents.host_agent.__main__ --host 0.0.0.0 --port 8083
      "
    restart: unless-stopped

  # UI - Port 12000
  # Depends on Host agent being ready
  ui:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_ui
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      HOST_AGENT_URL: http://host_agent:8083
    ports:
      - "12000:12000"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      host_agent:
        condition: service_started
    networks:
      - support_agents_network
    command: >
      sh -c "
        echo 'Initializing database...' &&
        python scripts/init_db.py --seed &&
        echo 'Waiting for Host agent to be ready...' &&
        sleep 5 &&
        echo 'Starting UI...' &&
        gunicorn --bind 0.0.0.0:12000 --timeout 120 ui.main:me
      "
    restart: unless-stopped

  # Memory Agent - Port 10005
  memory_agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: support_agents_memory
    env_file: .env
    environment:
      DATABASE_URL: postgresql://support_user:support_pass@postgres:5432/support_agents_db
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      GOOGLE_GENAI_USE_VERTEXAI: ${GOOGLE_GENAI_USE_VERTEXAI:-FALSE}
      GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT:-}
      GOOGLE_CLOUD_LOCATION: ${GOOGLE_CLOUD_LOCATION:-global}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      CHROMA_HOST: ${CHROMA_HOST:-host.docker.internal}
      CHROMA_PORT: ${CHROMA_PORT:-8000}
      LITELLM_MODEL: ${LITELLM_MODEL:-openai/gpt-4.1-mini}
      APP_URL: http://memory_agent:10005
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "10005:10005"
    volumes:
      - ./data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - support_agents_network
    command: python -m agents.memory_agent.__main__ --host 0.0.0.0 --port 10005
    restart: unless-stopped

volumes:
  postgres_data:

networks:
  support_agents_network:
    driver: bridge
